from openai import OpenAI
from app.core.config import settings
from app.schemas.ai import AIAnalysisResultOut, AIChatMessage
from app.db.database import get_database
from app.models.ai import AIConversation
from typing import List

# åˆ›å»ºOpenAIå®¢æˆ·ç«¯
client = None
if settings.OPENAI_API_KEY:
    client = OpenAI(
        api_key=settings.OPENAI_API_KEY,
        base_url=settings.OPENAI_BASE_URL
    )
    print("OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨é˜¿é‡Œäº‘DashScope API")
else:
    print("Warning: OpenAI API key is not set. AI functionalities will be mocked.")

async def analyze_mood_with_ai(text: str) -> AIAnalysisResultOut:
    if not settings.OPENAI_API_KEY or not client:
        print("OpenAI API key not set. Returning mock AI analysis.")
        return AIAnalysisResultOut(
            stress_index=0.5,
            mood_radar="æƒ…ç»ªå¹³ç¨³ï¼Œç•¥æœ‰æ³¢åŠ¨",
            explanation="æ ¹æ®æ‚¨çš„æè¿°ï¼Œæƒ…ç»ªå¤„äºä¸­ç­‰æ°´å¹³ï¼Œå»ºè®®ä¿æŒè§‚å¯Ÿã€‚",
            intervention_suggestion="å¯ä»¥å°è¯•è¿›è¡Œä¸€æ¬¡å†¥æƒ³ã€‚"
        )
    try:
        response = client.chat.completions.create(
            model="qwen-plus",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¿ƒç†å¥åº·åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æç”¨æˆ·æƒ…ç»ªå¹¶æä¾›å»ºè®®ã€‚"},
                {"role": "user", "content": f"è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…ç»ªï¼Œå¹¶ç»™å‡ºå‹åŠ›æŒ‡æ•°ï¼ˆ0-1ä¹‹é—´ï¼‰ã€æƒ…ç»ªé›·è¾¾æè¿°ã€è§£é‡Šå’Œå¹²é¢„å»ºè®®ï¼š\n\n{text}"
                }
            ],
            temperature=0.7,
            max_tokens=200
        )
        ai_response_content = response.choices[0].message.content

        # Attempt to parse the AI response into the desired format
        # This is a simplified parsing, a more robust solution might use regex or more structured prompts
        stress_index = 0.5
        mood_radar = "æƒ…ç»ªåˆ†æç»“æœ"
        explanation = ai_response_content
        intervention_suggestion = ""

        # Example of simple parsing (can be improved)
        if "å‹åŠ›æŒ‡æ•°:" in ai_response_content:
            try:
                stress_index = float(ai_response_content.split("å‹åŠ›æŒ‡æ•°:")[1].split("\n")[0].strip())
            except ValueError:
                pass
        if "æƒ…ç»ªé›·è¾¾:" in ai_response_content:
            mood_radar = ai_response_content.split("æƒ…ç»ªé›·è¾¾:")[1].split("\n")[0].strip()
        if "è§£é‡Š:" in ai_response_content:
            explanation = ai_response_content.split("è§£é‡Š:")[1].split("\n")[0].strip()
        if "å¹²é¢„å»ºè®®:" in ai_response_content:
            intervention_suggestion = ai_response_content.split("å¹²é¢„å»ºè®®:")[1].split("\n")[0].strip()

        return AIAnalysisResultOut(
            stress_index=stress_index,
            mood_radar=mood_radar,
            explanation=explanation,
            intervention_suggestion=intervention_suggestion
        )
    except Exception as e:
        print(f"Error calling OpenAI API: {e}")
        return AIAnalysisResultOut(
            stress_index=0.5,
            mood_radar="æƒ…ç»ªåˆ†ææš‚æ—¶ä¸å¯ç”¨",
            explanation="AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚",
            intervention_suggestion="å»ºè®®è¿›è¡Œæ·±å‘¼å¸ç»ƒä¹ ã€‚"
        )

async def generate_emergency_guidance(emotion_state: str, intensity: float) -> dict:
    """ç”Ÿæˆ90ç§’æƒ…ç»ªæ€¥æ•‘æŒ‡å¯¼"""
    if not settings.OPENAI_API_KEY or not client:
        return {
            "voice_script": "è¯·æ·±å‘¼å¸ï¼Œå¸æ°”4ç§’ï¼Œä¿æŒ4ç§’ï¼Œå‘¼æ°”6ç§’ã€‚é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œè®©è‡ªå·±å¹³é™ä¸‹æ¥ã€‚",
            "visual_prompt": "ä¸€ç‰‡å®é™çš„æ£®æ—ï¼Œé˜³å…‰é€è¿‡æ ‘å¶æ´’ä¸‹æ–‘é©³çš„å…‰å½±",
            "music_type": "nature_sounds",
            "duration": 90
        }
    
    try:
        print(f"ğŸ”¥ [DEBUG] å¼€å§‹è°ƒç”¨AIç”Ÿæˆæ€¥æ•‘æŒ‡å¯¼...")
        print(f"ğŸ”¥ [DEBUG] æƒ…ç»ªçŠ¶æ€: {emotion_state}, å¼ºåº¦: {intensity}")
        print(f"ğŸ”¥ [DEBUG] ä½¿ç”¨æ¨¡å‹: qwen-plus")
        print(f"ğŸ”¥ [DEBUG] API Base URL: {settings.OPENAI_BASE_URL}")
        print(f"ğŸ”¥ [DEBUG] API Keyå‰4ä½: {settings.OPENAI_API_KEY[:4]}****")
        
        # ä½¿ç”¨ç»“æ„åŒ–promptè¦æ±‚AIè¿”å›JSONæ ¼å¼
        response = client.chat.completions.create(
            model="qwen-plus",
            messages=[
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯ä¸“ä¸šçš„å¿ƒç†å±æœºå¹²é¢„å¸ˆã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼å›å¤ï¼ŒåŒ…å«voice_script(è¯­éŸ³å¼•å¯¼è¯)ã€visual_prompt(è§†è§‰åœºæ™¯æè¿°)ã€music_type(éŸ³ä¹ç±»å‹)ä¸‰ä¸ªå­—æ®µã€‚éŸ³ä¹ç±»å‹åªèƒ½ä»nature_soundsã€relaxing_pianoã€meditation_bellä¸­é€‰æ‹©ã€‚"
                },
                {
                    "role": "user", 
                    "content": f"ä¸º{emotion_state}æƒ…ç»ª(å¼ºåº¦{intensity}/10)è®¾è®¡90ç§’æ€¥æ•‘æ–¹æ¡ˆã€‚è¯·å›å¤JSONæ ¼å¼ï¼š{{\"voice_script\": \"æ¸©å’Œå…·ä½“çš„å‘¼å¸å’Œæ”¾æ¾å¼•å¯¼è¯\", \"visual_prompt\": \"å¹³é™è‡ªç„¶åœºæ™¯æè¿°\", \"music_type\": \"é€‚åˆçš„éŸ³ä¹ç±»å‹\"}}"
                }
            ],
            temperature=0.7,
            max_tokens=400,
            timeout=30  # è®¾ç½®30ç§’è¶…æ—¶
        )
        
        print(f"ğŸ‰ [DEBUG] AIè°ƒç”¨æˆåŠŸ! å“åº”çŠ¶æ€: {response}")
        print(f"ğŸ‰ [DEBUG] å“åº”å†…å®¹é•¿åº¦: {len(response.choices[0].message.content)}")
        print(f"ğŸ‰ [DEBUG] å“åº”åŸæ–‡: {response.choices[0].message.content}")
        
        # è®¡ç®—tokenä½¿ç”¨é‡
        if hasattr(response, 'usage'):
            print(f"ğŸ‰ [DEBUG] Tokenä½¿ç”¨é‡: {response.usage}")
        
        # è®¡ç®—è¯·æ±‚è€—æ—¶
        import time
        start_time = time.time()
        print(f"ğŸ‰ [DEBUG] å¤„ç†å“åº”å¼€å§‹æ—¶é—´: {start_time}")
        
        content = response.choices[0].message.content.strip()
        print(f"ğŸ” [DEBUG] AIå›å¤åŸæ–‡: {content}")  # è°ƒè¯•æ—¥å¿—
        print(f"ğŸ” [DEBUG] å¼€å§‹è§£æJSONå“åº”...")
        
        # å°è¯•è§£æJSONå“åº”
        import json
        import re
        
        try:
            # å¦‚æœå“åº”åŒ…å«markdownä»£ç å—ï¼Œæå–JSONéƒ¨åˆ†
            json_match = re.search(r'```(?:json)?\s*({[^}]*})\s*```', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                print(f"ğŸ” [DEBUG] ä»markdownä»£ç å—æå–JSON: {json_str}")
            else:
                # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                json_match = re.search(r'{[^{}]*"voice_script"[^{}]*}', content, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                    print(f"ğŸ” [DEBUG] ä½¿ç”¨æ­£åˆ™æå–JSON: {json_str}")
                else:
                    json_str = content
                    print(f"ğŸ” [DEBUG] ç›´æ¥ä½¿ç”¨å®Œæ•´å†…å®¹ä½œä¸ºJSON: {json_str}")
            
            ai_data = json.loads(json_str)
            print(f"âœ… [DEBUG] JSONè§£ææˆåŠŸ: {ai_data}")
            
            # éªŒè¯å’Œè§„èŒƒåŒ–æ•°æ®
            voice_script = ai_data.get("voice_script", "è¯·æ·±å‘¼å¸ï¼Œè®©èº«å¿ƒæ”¾æ¾ã€‚ä¸“æ³¨äºå½“ä¸‹ï¼Œæ„Ÿå—æ¯ä¸€æ¬¡å‘¼å¸å¸¦æ¥çš„å¹³é™ã€‚")
            visual_prompt = ai_data.get("visual_prompt", "ä¸€ç‰‡å®é™çš„æµ·æ»©ï¼Œæµ·æµªè½»æŸ”åœ°æ‹æ‰“ç€å²¸è¾¹")
            music_type = ai_data.get("music_type", "relaxing_piano")
            
            print(f"âœ… [DEBUG] æå–å­—æ®µ - è¯­éŸ³è„šæœ¬é•¿åº¦: {len(voice_script)}")
            print(f"âœ… [DEBUG] æå–å­—æ®µ - è§†è§‰æç¤ºé•¿åº¦: {len(visual_prompt)}")
            print(f"âœ… [DEBUG] æå–å­—æ®µ - éŸ³ä¹ç±»å‹: {music_type}")
            
            # ç¡®ä¿éŸ³ä¹ç±»å‹åœ¨å…è®¸èŒƒå›´å†…
            valid_music_types = ["nature_sounds", "relaxing_piano", "meditation_bell"]
            if music_type not in valid_music_types:
                print(f"âš ï¸  [DEBUG] éŸ³ä¹ç±»å‹ä¸åœ¨èŒƒå›´å†…ï¼Œä½¿ç”¨é»˜è®¤: {music_type} -> nature_sounds")
                music_type = "nature_sounds"
            
            result = {
                "voice_script": voice_script,
                "visual_prompt": visual_prompt,
                "music_type": music_type,
                "duration": 90
            }
            
            print(f"ğŸ‰ [DEBUG] æœ€ç»ˆè¿”å›ç»“æœ: {result}")
            return result
            
        except (json.JSONDecodeError, KeyError) as e:
            print(f"âŒ [DEBUG] JSONè§£æå¤±è´¥: {e}ï¼Œå°è¯•æ–‡æœ¬è§£æ")
            print(f"âŒ [DEBUG] å¤±è´¥çš„JSONå­—ç¬¦ä¸²: {json_str}")
            
            # å¤‡é€‰ï¼šæ–‡æœ¬è§£æ
            lines = content.split('\n')
            voice_script = "è¯·æ·±å‘¼å¸ï¼Œè®©èº«å¿ƒæ”¾æ¾ã€‚ä¸“æ³¨äºå½“ä¸‹è¿™ä¸€åˆ»ï¼Œæ„Ÿå—æ¯ä¸€æ¬¡å‘¼å¸å¸¦æ¥çš„å¹³é™ã€‚"
            visual_prompt = "ä¸€ç‰‡å®é™çš„æ£®æ—ï¼Œé˜³å…‰é€è¿‡æ ‘å¶æ´’ä¸‹æ¸©æš–çš„å…‰èŠ’"
            music_type = "nature_sounds"
            
            print(f"ğŸ”„ [DEBUG] å¼€å§‹æ–‡æœ¬è§£æï¼Œå…±{len(lines)}è¡Œ")
            
            for i, line in enumerate(lines):
                line = line.strip()
                print(f"ğŸ”„ [DEBUG] è§£æç¬¬{i+1}è¡Œ: {line}")
                if "è¯­éŸ³" in line or "voice" in line.lower():
                    if ":" in line:
                        voice_script = line.split(":", 1)[1].strip().strip('"').strip("'")
                        print(f"âœ… [DEBUG] æ‰¾åˆ°è¯­éŸ³è„šæœ¬: {voice_script}")
                elif "è§†è§‰" in line or "visual" in line.lower():
                    if ":" in line:
                        visual_prompt = line.split(":", 1)[1].strip().strip('"').strip("'")
                        print(f"âœ… [DEBUG] æ‰¾åˆ°è§†è§‰æç¤º: {visual_prompt}")
                elif "éŸ³ä¹" in line or "music" in line.lower():
                    if ":" in line:
                        music_candidate = line.split(":", 1)[1].strip().strip('"').strip("'")
                        if music_candidate in ["nature_sounds", "relaxing_piano", "meditation_bell"]:
                            music_type = music_candidate
                            print(f"âœ… [DEBUG] æ‰¾åˆ°éŸ³ä¹ç±»å‹: {music_type}")
            
            result = {
                "voice_script": voice_script,
                "visual_prompt": visual_prompt,
                "music_type": music_type,
                "duration": 90
            }
            
            print(f"ğŸ”„ [DEBUG] æ–‡æœ¬è§£æç»“æœ: {result}")
            return result
        
    except Exception as e:
        print(f"ğŸ’¥ [DEBUG] AIè°ƒç”¨å‘ç”Ÿå¼‚å¸¸: {type(e).__name__}: {str(e)}")
        print(f"ğŸ’¥ [DEBUG] å¼‚å¸¸è¯¦æƒ…: {repr(e)}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è¶…æ—¶é”™è¯¯
        if "timeout" in str(e).lower() or "timed out" in str(e).lower():
            print(f"â° [DEBUG] ç¡®è®¤ä¸ºè¶…æ—¶é”™è¯¯ï¼Œå¯èƒ½åŸå› :")
            print(f"   1. ç½‘ç»œè¿æ¥é—®é¢˜")
            print(f"   2. APIæœåŠ¡å™¨å“åº”æ…¢")
            print(f"   3. è¯·æ±‚å‚æ•°è¿‡å¤§")
            print(f"   4. APIé…ç½®é—®é¢˜")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯é”™è¯¯
        if "auth" in str(e).lower() or "401" in str(e) or "403" in str(e):
            print(f"ğŸ” [DEBUG] å¯èƒ½çš„è®¤è¯é—®é¢˜:")
            print(f"   API Key: {settings.OPENAI_API_KEY[:10]}...")
            print(f"   Base URL: {settings.OPENAI_BASE_URL}")
        
        print(f"Error generating emergency guidance: {e}")
        return {
            "voice_script": "è¯·æ·±å‘¼å¸ï¼Œå¸æ°”4ç§’ï¼Œä¿æŒ4ç§’ï¼Œå‘¼æ°”6ç§’ã€‚é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œè®©è‡ªå·±å¹³é™ä¸‹æ¥ã€‚",
            "visual_prompt": "ä¸€ç‰‡å®é™çš„æ£®æ—ï¼Œé˜³å…‰é€è¿‡æ ‘å¶æ´’ä¸‹æ–‘é©³çš„å…‰å½±",
            "music_type": "nature_sounds",
            "duration": 90
        }

async def generate_scenario_simulation(scenario_type: str, user_concerns: str) -> dict:
    """ç”Ÿæˆåœºæ™¯æ¨¡æ‹ŸæŒ‡å¯¼"""
    if not settings.OPENAI_API_KEY or not client:
        scenarios = {
            "exam": {
                "preparation_steps": ["æ·±å‘¼å¸3æ¬¡", "å›é¡¾çŸ¥è¯†è¦ç‚¹", "ç§¯æå¿ƒç†æš—ç¤º"],
                "mindset_guidance": "ä½ å·²ç»å……åˆ†å‡†å¤‡ï¼Œç›¸ä¿¡è‡ªå·±çš„èƒ½åŠ›",
                "visualization_script": "æƒ³è±¡è‡ªå·±åœ¨è€ƒåœºä¸Šå†·é™ç­”é¢˜çš„åœºæ™¯",
                "duration": 300
            },
            "interview": {
                "preparation_steps": ["æ•´ç†ç€è£…", "ç»ƒä¹ è‡ªæˆ‘ä»‹ç»", "æ¨¡æ‹Ÿé—®ç­”"],
                "mindset_guidance": "å±•ç°çœŸå®çš„è‡ªå·±ï¼Œé¢è¯•å®˜ä¹Ÿå¸Œæœ›æ‰¾åˆ°åˆé€‚çš„äºº",
                "visualization_script": "æƒ³è±¡è‡ªå·±è‡ªä¿¡åœ°ä¸é¢è¯•å®˜äº¤æµ",
                "duration": 300
            },
            "study": {
                "preparation_steps": ["æ¸…ç†æ¡Œé¢", "è®¾å®šå­¦ä¹ ç›®æ ‡", "å‡†å¤‡å­¦ä¹ ææ–™"],
                "mindset_guidance": "æ¯ä¸€åˆ†é’Ÿçš„åŠªåŠ›éƒ½åœ¨ä¸ºæ¢¦æƒ³æ·»ç –åŠ ç“¦",
                "visualization_script": "æƒ³è±¡è‡ªå·±ä¸“æ³¨å­¦ä¹ ï¼Œé€æ­¥æŒæ¡çŸ¥è¯†çš„æ»¡è¶³æ„Ÿ",
                "duration": 180
            }
        }
        return scenarios.get(scenario_type, scenarios["study"])
    
    try:
        print(f"ğŸ­ [DEBUG] å¼€å§‹è°ƒç”¨AIç”Ÿæˆåœºæ™¯æ¨¡æ‹Ÿ...")
        print(f"ğŸ­ [DEBUG] åœºæ™¯ç±»å‹: {scenario_type}, ç”¨æˆ·æ‹…å¿§: {user_concerns}")
        print(f"ğŸ­ [DEBUG] ä½¿ç”¨æ¨¡å‹: qwen-plus")
        
        response = client.chat.completions.create(
            model="qwen-plus",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„å¿ƒç†æ•™ç»ƒï¼Œæ“…é•¿å¸®åŠ©å­¦ç”Ÿå¿«é€Ÿè¿›å…¥æœ€ä½³çŠ¶æ€ã€‚è¯·æä¾›å…·ä½“çš„å‡†å¤‡æ­¥éª¤ã€å¿ƒæ€è°ƒæ•´å’Œå¯è§†åŒ–å¼•å¯¼ã€‚"},
                {"role": "user", "content": f"åœºæ™¯ç±»å‹ï¼š{scenario_type}ï¼Œç”¨æˆ·æ‹…å¿§ï¼š{user_concerns}ã€‚è¯·è®¾è®¡è¿›å…¥çŠ¶æ€çš„æ–¹æ¡ˆï¼ŒåŒ…å«ï¼š1)å…·ä½“å‡†å¤‡æ­¥éª¤ 2)å¿ƒæ€è°ƒæ•´æŒ‡å¯¼ 3)å¯è§†åŒ–å¼•å¯¼è„šæœ¬"}
            ],
            temperature=0.7,
            max_tokens=400,
            timeout=30
        )
        
        print(f"ğŸ‰ [DEBUG] åœºæ™¯æ¨¡æ‹ŸAIè°ƒç”¨æˆåŠŸ!")
        print(f"ğŸ‰ [DEBUG] å“åº”å†…å®¹: {response.choices[0].message.content}")
        
        content = response.choices[0].message.content
        
        # ç®€å•è§£æå“åº”å†…å®¹
        preparation_steps = []
        mindset_guidance = content
        visualization_script = "æƒ³è±¡æˆåŠŸå®Œæˆä»»åŠ¡çš„åœºæ™¯"
        
        # å°è¯•ä»å“åº”ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯
        lines = content.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if 'å‡†å¤‡' in line or 'æ­¥éª¤' in line:
                current_section = 'preparation'
            elif 'å¿ƒæ€' in line or 'æŒ‡å¯¼' in line:
                current_section = 'mindset'
            elif 'å¯è§†åŒ–' in line or 'æƒ³è±¡' in line:
                current_section = 'visualization'
            elif line and current_section == 'preparation' and ('1.' in line or '2.' in line or '3.' in line or '-' in line):
                # æå–å‡†å¤‡æ­¥éª¤
                step = line.replace('1.', '').replace('2.', '').replace('3.', '').replace('-', '').strip()
                if step:
                    preparation_steps.append(step)
        
        if not preparation_steps:
            preparation_steps = ["å‡†å¤‡ç¬¬ä¸€æ­¥", "å‡†å¤‡ç¬¬äºŒæ­¥", "å‡†å¤‡ç¬¬ä¸‰æ­¥"]
        
        result = {
            "preparation_steps": preparation_steps[:3],  # æœ€å¤š3ä¸ªæ­¥éª¤
            "mindset_guidance": mindset_guidance,
            "visualization_script": visualization_script,
            "duration": 300
        }
        
        print(f"ğŸ­ [DEBUG] åœºæ™¯æ¨¡æ‹Ÿæœ€ç»ˆç»“æœ: {result}")
        return result
        
    except Exception as e:
        print(f"ğŸ’¥ [DEBUG] åœºæ™¯æ¨¡æ‹ŸAIè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {str(e)}")
        print(f"ğŸ’¥ [DEBUG] å¼‚å¸¸è¯¦æƒ…: {repr(e)}")
        
        # æ£€æŸ¥é”™è¯¯ç±»å‹
        if "timeout" in str(e).lower():
            print(f"â° [DEBUG] åœºæ™¯æ¨¡æ‹Ÿè¶…æ—¶é”™è¯¯")
        
        print(f"Error generating scenario simulation: {e}")
        return {
            "preparation_steps": ["æ·±å‘¼å¸è°ƒæ•´", "æ˜ç¡®ç›®æ ‡", "ç§¯ææš—ç¤º"],
            "mindset_guidance": "ç›¸ä¿¡è‡ªå·±çš„èƒ½åŠ›ï¼Œä¸€æ­¥æ­¥æ¥",
            "visualization_script": "æƒ³è±¡è‡ªå·±æˆåŠŸå®Œæˆç›®æ ‡çš„åœºæ™¯",
            "duration": 300
        }

async def get_ai_chat_response(messages: List[AIChatMessage], user_id: str) -> str:
    if not settings.OPENAI_API_KEY or not client:
        print("OpenAI API key not set. Returning mock AI chat response.")
        return "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·è®¾ç½®OpenAI APIå¯†é’¥ã€‚"

    db = get_database()
    # Load previous conversation history for context
    conversation_history = []
    # In a real app, you might limit the history or summarize it
    async for conv_msg in db["ai_conversations"].find({"user_id": user_id}).sort("created_at", -1).limit(5):
        conversation_history.extend(conv_msg["messages"])

    full_messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè€ƒç ”å¿ƒç†å¥åº·åŠ©æ‰‹ï¼Œä¸“æ³¨äºæä¾›æƒ…æ„Ÿæ”¯æŒå’Œå­¦ä¹ å»ºè®®ã€‚"}
    ]
    # Add historical messages, ensuring they are in the correct format
    for msg in conversation_history:
        full_messages.append({"role": msg["role"], "content": msg["content"]})
    # Add current messages
    for msg in messages:
        full_messages.append({"role": msg.role, "content": msg.content})

    try:
        response = client.chat.completions.create(
            model="qwen-plus",
            messages=full_messages,
            temperature=0.7,
            max_tokens=500
        )
        ai_response_content = response.choices[0].message.content

        # Save current interaction to conversation history
        new_conversation = AIConversation(
            user_id=user_id,
            messages=[msg.dict() for msg in messages] + [{
                "role": "assistant",
                "content": ai_response_content
            }]
        )
        await db["ai_conversations"].insert_one(new_conversation.dict(by_alias=True, exclude_unset=True))

        return ai_response_content
    except Exception as e:
        print(f"Error calling OpenAI API for chat: {e}")
        return "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"

